{"cells":[{"metadata":{"id":"DHqXFHFHTk5m","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"id":"Af87OrdlRcqh","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"kaggle = True  ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"Ryh5dth8Q73g","colab_type":"code","colab":{}},"cell_type":"code","source":"if kaggle:\n  # This Python 3 environment comes with many helpful analytics libraries installed\n  # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n  # For example, here's several helpful packages to load in \n\n  import numpy as np # linear algebra\n  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n  # Input data files are available in the \"../input/\" directory.\n  # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n  import os\n  for dirname, _, filenames in os.walk('/kaggle/input'):\n      for filename in filenames:\n          print(os.path.join(dirname, filename))\n\n  # Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"id":"wAIAN7MORaEs","colab_type":"code","outputId":"061ec7c5-cecb-48e2-e3d9-fd7bfda6629f","colab":{"base_uri":"https://localhost:8080/","height":386},"trusted":true},"cell_type":"code","source":"if not kaggle:\n  !pip install kaggle\n  from getpass import getpass\n  import os\n  user = 'ahmadelsallab'\n  key = '6b7ffe97ff5bc0656e325b746b72fa31'\n\n  if '.kaggle' not in os.listdir('/root'):\n      !mkdir ~/.kaggle\n  !touch /root/.kaggle/kaggle.json\n  !chmod 666 /root/.kaggle/kaggle.json\n  with open('/root/.kaggle/kaggle.json', 'w') as f:\n      f.write('{\"username\":\"%s\",\"key\":\"%s\"}' % (user, key))\n  !chmod 600 /root/.kaggle/kaggle.json\n\n  !kaggle competitions download -c ashrae-energy-prediction\n\n  !unzip -n train.csv.zip\n  !unzip -n weather_train.csv.zip\n  !unzip -n building_metadata.csv.zip","execution_count":null,"outputs":[]},{"metadata":{"id":"FKcSc5WWRI4A","colab_type":"code","outputId":"cf634b5d-4416-4b7d-93c8-984a04649dfb","colab":{"base_uri":"https://localhost:8080/","height":383},"trusted":true},"cell_type":"code","source":"\ndef load_train_data():\n  if kaggle:\n    train_path = '/kaggle/input/ashrae-energy-prediction/train.csv'\n    building_train_path = '/kaggle/input/ashrae-energy-prediction/building_metadata.csv'\n    weather_train_path = '/kaggle/input/ashrae-energy-prediction/weather_train.csv'\n  else:\n    train_path = 'train.csv'\n    building_train_path = 'building_metadata.csv'\n    weather_train_path = 'weather_train.csv'\n\n  return pd.merge(pd.merge(pd.read_csv(train_path), pd.read_csv(building_train_path), on='building_id', how='left'), pd.read_csv(weather_train_path), on=['timestamp','site_id'], how='left')\ntrain_df = load_train_data()\ntrain_df.head()\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"kDGJlP4dQ73z","colab_type":"code","colab":{}},"cell_type":"code","source":"\ntrain_df.meter_reading = train_df.meter_reading.apply(np.log1p)","execution_count":null,"outputs":[]},{"metadata":{"id":"wA_d-QKQAt_I","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"train_df.square_feet = train_df.square_feet.apply(np.log1p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"5r7lptAxQ735","colab_type":"code","colab":{}},"cell_type":"code","source":"'''Function to reduce the DF size'''\n# source: https://www.kaggle.com/kernels/scriptcontent/3684066/download\n\ndef reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() / 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"LCleRh7tQ74D","colab_type":"code","colab":{}},"cell_type":"code","source":"'''Variable Description'''\ndef description(df):\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.iloc[0].values\n    summary['Second Value'] = df.iloc[1].values\n    summary['Third Value'] = df.iloc[2].values\n    return summary","execution_count":null,"outputs":[]},{"metadata":{"id":"mztwu1hjO9qm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"outputId":"230a6139-177f-4223-a03c-8a567e59ca17","trusted":true},"cell_type":"code","source":"train_df = reduce_mem_usage(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"P0d-vamDQ74I","colab_type":"code","outputId":"a9dfbc56-8abc-483c-85cc-710bd7ab0970","colab":{"base_uri":"https://localhost:8080/","height":521}},"cell_type":"code","source":"description(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"ZHF6BtqQQ74M","colab_type":"code","colab":{}},"cell_type":"code","source":"train_df[\"timestamp\"] = pd.to_datetime(train_df[\"timestamp\"])\ntrain_df[\"hour\"] = train_df[\"timestamp\"].dt.hour\ntrain_df[\"day\"] = train_df[\"timestamp\"].dt.day\ntrain_df[\"weekday\"] = train_df[\"timestamp\"].dt.weekday_name \ntrain_df[\"month\"] = train_df[\"timestamp\"].dt.month\ntrain_df['year'] = train_df['timestamp'].dt.year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"oGYeiD7CQ74R","colab_type":"code","outputId":"38c50338-3268-404c-8802-4c6a813402eb","colab":{"base_uri":"https://localhost:8080/","height":299}},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"8rsPg6InQ74X","colab_type":"code","colab":{}},"cell_type":"code","source":"month_to_season = lambda month:(month%12 + 3)//3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"OBMra8EXQ74b","colab_type":"code","colab":{}},"cell_type":"code","source":"train_df['season'] = train_df.month.apply(month_to_season)","execution_count":null,"outputs":[]},{"metadata":{"id":"t1XTAnzwIidP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":698},"outputId":"3c498744-8202-4a0a-ff9a-f0e6649ec536","trusted":true},"cell_type":"code","source":"description(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"9FZVH-6LQ74h","colab_type":"code","colab":{}},"cell_type":"code","source":"import lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"K_i_o9tOQ74m","colab_type":"code","colab":{}},"cell_type":"code","source":"y_train = train_df.meter_reading","execution_count":null,"outputs":[]},{"metadata":{"id":"8R87s-_a5mzx","colab_type":"text"},"cell_type":"markdown","source":"Note that: LGBM will ignore missing values in the features vector.\nhttps://www.kaggle.com/c/home-credit-default-risk/discussion/57918\n\nsemissing=false, which disables handling for missing values. You can also use the zeroas_missing option to change behavior.\n\nSo we need to handle missing values for better performance. Especially for __temprature values__"},{"metadata":{"trusted":true,"id":"5bcrFReGQ74s","colab_type":"code","colab":{}},"cell_type":"code","source":"features = ['meter',\n            'site_id',\n            'building_id',\n            'primary_use',\n            'square_feet',\n            #'year_built',\n            #'floor_count',\n            #'air_temperature',\n            #'dew_temperature',\n            #'cloud_coverage',\n            #'wind_direction',\n            #'wind_speed',\n            #'precip_depth_1_hr',\n            #'hour',\n            #'weekday',\n            #'day',\n            'month',\n            'season'\n            ] # meter must be added, since not all features corr to meter_reading are the same. Same for site_id with less priority\ndef select_features(df):    \n    return df[features] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"2yqbU8afQ74w","colab_type":"code","colab":{}},"cell_type":"code","source":"\nx_train = select_features(train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"4qFycIs7Q741","colab_type":"code","colab":{}},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ndef prep_features(dataset):\n    features = []; categorical_features = []\n    num_of_columns = dataset.shape[1]\n \n    for i in range(0, num_of_columns):\n        column_name = dataset.columns[i]\n        column_type = dataset[column_name].dtypes\n        '''\n        if i != num_of_columns - 1: #skip target\n            features.append(column_name)\n        '''\n        features.append(column_name)\n        if column_type == 'object':\n            le.fit(dataset[column_name])\n            feature_classes = list(le.classes_)\n            encoded_feature = le.transform(dataset[column_name])\n            dataset[column_name] = pd.DataFrame(encoded_feature)\n            '''\n            if i != num_of_columns - 1: #skip target\n                categorical_features.append(column_name)\n            '''\n            categorical_features.append(column_name)\n    '''\n    if is_regression == False and i == num_of_columns - 1:\n        num_of_classes = len(feature_classes)\n    else:\n        num_of_classes = 1\n    '''\n    return dataset, features, categorical_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"WVAK6OMuQ746","colab_type":"code","colab":{}},"cell_type":"code","source":"\nx_train, features, categorical_features = prep_features(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"eL3wDPOcQ74_","colab_type":"code","colab":{}},"cell_type":"code","source":"from sklearn.model_selection import KFold, train_test_split\n# Make validation set based on train_test_split\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"iuaZ-KCuQ75E","colab_type":"code","colab":{}},"cell_type":"code","source":"lgb_train = lgb.Dataset(x_train, y_train\n ,feature_name = features#+categorical_features\n #, categorical_feature = categorical_features\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"MVLOUpjHQ75I","colab_type":"code","colab":{}},"cell_type":"code","source":"params = {\n 'task': 'train'\n , 'boosting_type': 'gbdt'\n , 'objective': 'regression'# if is_regression == True else 'multiclass'\n , 'num_class': 1\n , 'metric': 'rmsle'# if is_regression == True else 'multi_logloss'\n , 'min_data': 1\n , 'verbose': 1\n}\n \ngbm = lgb.train(params, lgb_train, num_boost_round=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"XTR_kXsVQ75Q","colab_type":"code","outputId":"fe0bc1f8-412c-42e4-c4db-1039fa87779a","colab":{"base_uri":"https://localhost:8080/","height":394}},"cell_type":"code","source":"!pip install graphviz\n\nimport matplotlib.pyplot as plt\nax = lgb.plot_importance(gbm, max_num_features=10)\nplt.show()\n \nax = lgb.plot_tree(gbm)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"kjdokTg6Q75Z","colab_type":"code","outputId":"f40e6a0e-07bf-4887-f601-0028698ee944","colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error as msle, mean_squared_error as mse\ny_pred = gbm.predict(x_val)\nscore = np.sqrt(mse(y_val, y_pred))# we use mse not msle since we already make y_val as np.log1p and so the y_pred\nprint('Val MSE = ', score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"PLijTPVsQ75h","colab_type":"code","colab":{}},"cell_type":"code","source":"del train_df\ndel x_train\ndel x_val","execution_count":null,"outputs":[]},{"metadata":{"id":"zQ2E7dkrSXXE","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"def load_test_data():\n  if kaggle:\n    test_path = '/kaggle/input/ashrae-energy-prediction/test.csv'\n    weather_test_path = '/kaggle/input/ashrae-energy-prediction/weather_test.csv'\n    building_train_path = '/kaggle/input/ashrae-energy-prediction/building_metadata.csv'\n  else:\n    test_path = 'test.csv'\n    weather_test_path = 'weather_test.csv'    \n    building_train_path = 'building_metadata.csv'\n    \n  \n  return pd.merge(pd.merge(pd.read_csv(test_path), pd.read_csv(building_train_path), on='building_id', how='left'), pd.read_csv(weather_test_path), on=['timestamp','site_id'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"ulx7HKFgQ75n","colab_type":"code","outputId":"69b7f83a-ea2d-4229-90f0-138e7414a9d9","colab":{"base_uri":"https://localhost:8080/","height":105}},"cell_type":"code","source":"\nif not kaggle:\n  !unzip -n test.csv.zip\n  !unzip -n weather_test.csv.zip\n  \ntest_df = load_test_data()\n# Test prep and features extraction\n\n\ntest_df = reduce_mem_usage(test_df)\n\ntest_df[\"timestamp\"] = pd.to_datetime(test_df[\"timestamp\"])\ntest_df[\"hour\"] = test_df[\"timestamp\"].dt.hour\ntest_df[\"day\"] = test_df[\"timestamp\"].dt.day\ntest_df[\"weekday\"] = test_df[\"timestamp\"].dt.weekday_name \ntest_df[\"month\"] = test_df[\"timestamp\"].dt.month\ntest_df['year'] = test_df['timestamp'].dt.year\n\ntest_df['season'] = test_df.month.apply(month_to_season)\n#test_df = reduce_mem_usage(test_df)\n\nx_test = select_features(test_df)\ndel test_df\nx_test, features, categorical_features = prep_features(x_test)","execution_count":null,"outputs":[]},{"metadata":{"id":"lYLiT0qUQ75s","colab_type":"text"},"cell_type":"markdown","source":"The score predicts to return the abs meter reading, while we predict log(p) + 1. So we must make exp(pred) - 1.\n\nThis is all done using np.expm1 (m1 = minus 1)"},{"metadata":{"id":"CKaTqe5ZxRkh","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"preds = np.expm1(gbm.predict(x_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"xa4QXiPVQ75t","colab_type":"code","outputId":"7a02a3f9-17d8-4611-887c-468ffc6388fa","colab":{"base_uri":"https://localhost:8080/","height":230}},"cell_type":"code","source":"#!unzip -n sample_submission.csv.zip\nif kaggle:\n  sample = pd.read_csv(\"/kaggle/input/ashrae-energy-prediction/sample_submission.csv\")\nelse:\n  !unzip -n sample_submission.csv.zip\n  sample = pd.read_csv(\"sample_submission.csv\")\nsample['meter_reading'] = preds #np.expm1(gbm.predict(x_test))\nsample.to_csv('submission.csv', index=False)\nsample.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"name":"ASHRAE_model_all features_lgbm.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}